{"cells":[{"cell_type":"markdown","source":["Mounting Drive to save model and read files"],"metadata":{"id":"C1WjYPk-Frpf"}},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17015,"status":"ok","timestamp":1652641476910,"user":{"displayName":"Rohith Rajesh","userId":"09025646982647274569"},"user_tz":-330},"id":"421mtljTH8IW","outputId":"35c49433-853c-4872-8263-f86837d2d693"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1652641483805,"user":{"displayName":"Rohith Rajesh","userId":"09025646982647274569"},"user_tz":-330},"id":"0NZYQqYuH8uI","outputId":"1b1d8d57-fcb0-4be3-a484-3fd9ceda7123"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Assignment3\n"]}],"source":["cd /content/drive/MyDrive/Colab Notebooks/Assignment3\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":518,"status":"ok","timestamp":1652641484846,"user":{"displayName":"Rohith Rajesh","userId":"09025646982647274569"},"user_tz":-330},"id":"hNEC10LtIOv6","outputId":"25dd55d9-34ae-413f-84e6-b2fe5b09becc"},"outputs":[{"output_type":"stream","name":"stdout","text":["'AOMML Assignment3.ipynb'   model_84_9.pickle\t\t model_87_2000.pickle\n"," Dataset.csv\t\t    model_87_2000_later.pickle\t model_fin.pickle\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":3177,"status":"ok","timestamp":1652641488020,"user":{"displayName":"Rohith Rajesh","userId":"09025646982647274569"},"user_tz":-330},"id":"lWBkbNABIPvf"},"outputs":[],"source":["import numpy as np\n","\n","import os\n","import csv\n","from keras.datasets import imdb\n","from sklearn.metrics import log_loss\n","from scipy.special import expit"]},{"cell_type":"markdown","source":["**Loading the Dataset**"],"metadata":{"id":"9aDLBgETFyHz"}},{"cell_type":"code","source":["num_words= 100\n"],"metadata":{"id":"UMQLVmWcZwiR","executionInfo":{"status":"ok","timestamp":1652641488022,"user_tz":-330,"elapsed":30,"user":{"displayName":"Rohith Rajesh","userId":"09025646982647274569"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5290,"status":"ok","timestamp":1652641493287,"user":{"displayName":"Rohith Rajesh","userId":"09025646982647274569"},"user_tz":-330},"id":"ESQSpyceIVPp","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bb368c2d-9e34-4e04-96e1-bc842baa76fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17465344/17464789 [==============================] - 0s 0us/step\n","17473536/17464789 [==============================] - 0s 0us/step\n"]}],"source":["(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=num_words)\n","# print(testing_data.shape)\n","# data = np.concatenate((training_data, testing_data), axis=0)\n","# targets = np.concatenate((training_targets, testing_targets), axis=0)\n","\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":821,"status":"ok","timestamp":1652641494103,"user":{"displayName":"Rohith Rajesh","userId":"09025646982647274569"},"user_tz":-330},"id":"IlCxDnqqInZD"},"outputs":[],"source":["def vectorize(sequences, dimension = 5000):\n","  results = np.zeros((len(sequences), dimension))\n","  for i, sequence in enumerate(sequences):\n","    results[i, sequence] = 1\n","  return results\n"," \n","train_data = vectorize(training_data,dimension=num_words)\n","train_targets = np.array(training_targets).astype(\"float32\")\n","testing_data = vectorize(testing_data,dimension=num_words)\n","testing_targets = np.array(testing_targets).astype(\"float32\")\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1652641494104,"user":{"displayName":"Rohith Rajesh","userId":"09025646982647274569"},"user_tz":-330},"id":"Ckip5ENDIsdM"},"outputs":[],"source":[""]},{"cell_type":"markdown","source":["**Splitting into train and test**"],"metadata":{"id":"nzW8sFtNF5dh"}},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1652641494105,"user":{"displayName":"Rohith Rajesh","userId":"09025646982647274569"},"user_tz":-330},"id":"U_IZ6CB1MQjn"},"outputs":[],"source":["\n","from sklearn.model_selection import train_test_split\n","# x_train,x_test,y_train,y_test = train_test_split(data,targets,shuffle=True,stratify=targets,random_state=42,test_size=0.1)\n","x_train,x_val,y_train,y_val = train_test_split(train_data,train_targets,shuffle=True,stratify=train_targets,random_state=42,test_size=0.1)\n","\n","\n"]},{"cell_type":"code","source":["x_test=testing_data\n","y_test=testing_targets"],"metadata":{"id":"24tqcnTdS3Pq","executionInfo":{"status":"ok","timestamp":1652641494105,"user_tz":-330,"elapsed":9,"user":{"displayName":"Rohith Rajesh","userId":"09025646982647274569"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1652641494106,"user":{"displayName":"Rohith Rajesh","userId":"09025646982647274569"},"user_tz":-330},"id":"BjFClKC8IJJR"},"outputs":[],"source":["#COnverting from Nxf to fXN where f is number of features and N is number of samples\n","x_train = x_train.T\n","y_train=y_train\n","x_test = x_test.T\n","y_test=y_test\n","x_val=x_val.T\n","y_val=y_val\n"]},{"cell_type":"markdown","source":["**ANN Code**"],"metadata":{"id":"sjomK1c4GMbP"}},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":683,"status":"ok","timestamp":1652641533544,"user":{"displayName":"Rohith Rajesh","userId":"09025646982647274569"},"user_tz":-330},"id":"Zn6QbM7wMV6U"},"outputs":[],"source":["import copy\n","from sklearn.utils import shuffle\n","def accuracy(y_pred,y_true):\n","  return y_pred[y_pred==y_true].shape[0]/y_pred.shape[0]\n","\n","class ANN:\n","  def __init__(self,input_neurons=10000,output_neurons=1,hidden_neurons=[8,8],hidden_activation='sigmoid'):\n","    self.layers=[input_neurons]\n","    np.random.seed(0)\n","    for _ in range(len(hidden_neurons)):\n","      self.layers.append(hidden_neurons[_]) # adding bias in each layer\n","    self.layers.append(output_neurons)\n","    self.w=[] # struct for storing weights of each layer\n","    self.b=[]\n","    self.buff_z=[] # buffers to store intermediate activations and pre-activations for gradient computation\n","    self.buff_a=[]\n","    self.hidden_activation=hidden_activation\n","    self.err_buff=[[0]*neurons for neurons in self.layers] # buffer for storing gradient error for each neuron of the network for backprop\n","    for n in range(len(self.layers)-1):\n","      # random init of weights and zero init of biases\n","      w_l=np.random.randn(self.layers[n+1],self.layers[n])*0.1\n","      b_l=np.zeros(self.layers[n+1])\n","      # b_l=np.ones(self.layers[n+1])\n","      self.w.append(w_l)\n","      self.b.append(b_l)\n","    \n","\n","  def sigmoid(self,x):\n","    return 1/(1+np.exp(-x))\n","\n","  def activation(self,x,last=False):\n","    if last:\n","      # Last layer is fixed to sigmoid\n","      return self.sigmoid(x)\n","    if self.hidden_activation == 'sigmoid':\n","      return 1/(1+np.exp(-x))\n","    elif self.hidden_activation=='relu':\n","      xr=np.copy(x).flatten()\n","      xr[xr<=0] = 0\n","      return xr.reshape(x.shape)\n","  def forward(self,X,train=True):\n","    # Z=np.zeros((self.layers[-1],X.shape[1]))\n","    Z=copy.deepcopy(X)\n","    if train:\n","      self.buff_a=[]\n","      self.buff_z=[]\n","      self.buff_a.append(Z) # storing input as the first activation\n","      self.buff_z.append(0)\n","    for i in range(0,len(self.layers)-1):\n","      # Z=np.vstack((np.ones((1,Z.shape[1])),Z))\n","      w=self.w[i]\n","      b=np.dstack([self.b[i]]*X.shape[1]).squeeze(0)\n","      in_shape=Z.shape\n","      Z = np.matmul(w,Z) + b\n","      if train: self.buff_z.append(Z)\n","      if i== len(self.layers)-2:\n","        Z = self.activation(Z,last=True)\n","      else:\n","        Z= self.activation(Z)      \n","      if train: self.buff_a.append(Z) \n","    return Z\n","\n","\n","  def dz(self,a,y):\n","    # dC/dZ -- dC/dA * dA/dZ (for BCE loss and sigmoid activation)\n","    return ( a-y ) / y.shape[0]\n","\n","  def fdash_a(self,a):\n","    if self.hidden_activation == 'sigmoid':\n","      return a*(1-a)\n","    elif self.hidden_activation =='relu':\n","      ac= np.copy(a)\n","      ac=ac.flatten()\n","      return (np.where(ac>0,1,0)).reshape(a.shape)\n","      \n","  def loss(self,a,y_train):\n","    return log_loss(y_train.flatten(),a.flatten())\n","  \n","  def compute_error(self,y):\n","    last_layer=self.dz(self.buff_a[-1],y)\n","    err_buff=[0]*(len(self.layers)-1)\n","    err_buff[-1]=last_layer # [_,_,_,del3]\n","    for l in range(len(self.layers)-2,0,-1):\n","      err=np.matmul(self.w[l].T,err_buff[l]) * self.fdash_a(self.buff_a[l+1])\n","      err_buff[l-1] =err\n","    return err_buff\n","\n","  def backprop(self,y_train,lr):\n","    n=y_train.shape[0]\n","    err=self.compute_error(y_train)\n","    self.dw=[]\n","    self.db=[]\n","    for i in range(0,len(self.layers)-1):\n","      # print(err[i].shape,self.buff_a[i].shape)\n","      self.dw.append(np.matmul(err[i],self.buff_a[i].T)/n)\n","      self.db.append(err[i].mean(axis=1))\n","\n","\n","  def fit(self,x_train,y_train,x_val,y_val,epochs=100,lr=0.1,batch_size=4):\n","    n=x_train.shape[1]\n","    # print(x_train.shape,y_train.shape)\n","    for _ in range(epochs):\n","      train_loss=0\n","      train_accuracy=0\n","      x_train,y_train=shuffle(copy.deepcopy(x_train.T),copy.deepcopy(y_train.T))\n","      x_train=x_train.T\n","      y_train=y_train.T\n","      for batch_idx in range(0,n,batch_size):\n","        x_batch,y_batch=x_train[:,batch_idx:batch_idx+batch_size],y_train[batch_idx:batch_idx+batch_size]\n","        self.forward(x_batch)\n","        train_loss += self.loss(self.buff_a[-1],y_batch) # calculate loss with the last activation\n","        train_pred= self.float_to_bin(self.buff_a[-1])\n","        train_accuracy += self.accuracy(train_pred,y_batch)\n","        self.backprop(y_batch,lr)\n","        for i in range(len(self.w)):\n","          self.w[i] -=lr*self.dw[i]\n","          self.b[i] -=lr*self.db[i]\n","      \n","      \n","      y_pred=self.float_to_bin(self.forward(x_val,train=False))\n","      print(f\"Epoch {_}: Training Loss : {train_loss/(x_train.shape[1]/batch_size)}, Train Acc:{train_accuracy/(x_train.shape[1]/batch_size)} Val Acc : {self.accuracy(y_pred,y_val)}\")\n","\n","\n","  def float_to_bin(self,y):\n","    # converts floats of final layer to predictions {0,1}\n","    return np.where(y.flatten()>=0.5,0,1)\n","\n","    # pass\n","  def predict(self,x_test):\n","    y_pred=self.forward(x_test,train=False)\n","    y_pred= self.float_to_bin(y_pred)\n","    return y_pred\n","\n","  # def load(weights,bias):\n","\n","  def accuracy(self,y_pred,y_test):\n","    y_pred=y_pred.flatten()\n","    return np.sum(np.abs(y_pred-y_test))/y_pred.shape[0]\n","\n"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1652641533545,"user":{"displayName":"Rohith Rajesh","userId":"09025646982647274569"},"user_tz":-330},"id":"-dk_I6R9M6Y-"},"outputs":[],"source":["model=ANN(input_neurons=x_train.shape[0],hidden_activation='relu')"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-kiJBTe3PHZ4","executionInfo":{"status":"ok","timestamp":1652641556826,"user_tz":-330,"elapsed":23286,"user":{"displayName":"Rohith Rajesh","userId":"09025646982647274569"}},"outputId":"a28c3c14-bf8a-45d3-e1c9-e9de88e537b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0: Training Loss : 0.6940340700468027, Train Acc:0.4934826666666667 Val Acc : 0.4844\n","Epoch 1: Training Loss : 0.694025621495679, Train Acc:0.5017208888888889 Val Acc : 0.4844\n","Epoch 2: Training Loss : 0.6940186277336483, Train Acc:0.5051111111111111 Val Acc : 0.4872\n","Epoch 3: Training Loss : 0.6940115271328638, Train Acc:0.5003555555555556 Val Acc : 0.4912\n","Epoch 4: Training Loss : 0.6940044949219311, Train Acc:0.5044462222222222 Val Acc : 0.4964\n","Epoch 5: Training Loss : 0.6939941066155109, Train Acc:0.5119751111111112 Val Acc : 0.4964\n","Epoch 6: Training Loss : 0.6939856316839219, Train Acc:0.511632 Val Acc : 0.5008\n","Epoch 7: Training Loss : 0.6939768600880649, Train Acc:0.5147235555555556 Val Acc : 0.5044\n","Epoch 8: Training Loss : 0.6939699852940542, Train Acc:0.5143928888888889 Val Acc : 0.4944\n","Epoch 9: Training Loss : 0.6939604335780084, Train Acc:0.509296 Val Acc : 0.5036\n","Epoch 10: Training Loss : 0.6939527678972431, Train Acc:0.5129528888888889 Val Acc : 0.5044\n","Epoch 11: Training Loss : 0.6939423961739629, Train Acc:0.5171431111111111 Val Acc : 0.5088\n","Epoch 12: Training Loss : 0.6939325427981794, Train Acc:0.5182328888888889 Val Acc : 0.5064\n","Epoch 13: Training Loss : 0.6939214215189586, Train Acc:0.5179182222222222 Val Acc : 0.5076\n","Epoch 14: Training Loss : 0.6939098697268666, Train Acc:0.5251146666666666 Val Acc : 0.5044\n","Epoch 15: Training Loss : 0.6938957419823272, Train Acc:0.522672 Val Acc : 0.508\n","Epoch 16: Training Loss : 0.6938826480616138, Train Acc:0.5283680000000001 Val Acc : 0.514\n","Epoch 17: Training Loss : 0.6938697988603669, Train Acc:0.5302791111111111 Val Acc : 0.5164\n","Epoch 18: Training Loss : 0.6938534126449781, Train Acc:0.5299288888888889 Val Acc : 0.5148\n","Epoch 19: Training Loss : 0.6938368492411433, Train Acc:0.5254008888888889 Val Acc : 0.5168\n","Epoch 20: Training Loss : 0.6938207453556758, Train Acc:0.534016 Val Acc : 0.5196\n","Epoch 21: Training Loss : 0.69380060053373, Train Acc:0.5348764444444444 Val Acc : 0.5208\n","Epoch 22: Training Loss : 0.6937790312197981, Train Acc:0.5373884444444444 Val Acc : 0.5224\n","Epoch 23: Training Loss : 0.6937563526420116, Train Acc:0.5410648888888888 Val Acc : 0.5228\n","Epoch 24: Training Loss : 0.6937297985450385, Train Acc:0.5426773333333333 Val Acc : 0.5236\n","Epoch 25: Training Loss : 0.6937043364171651, Train Acc:0.5441706666666667 Val Acc : 0.524\n","Epoch 26: Training Loss : 0.6936730895677706, Train Acc:0.5430897777777778 Val Acc : 0.5288\n","Epoch 27: Training Loss : 0.6936406713664496, Train Acc:0.5475982222222222 Val Acc : 0.526\n","Epoch 28: Training Loss : 0.6936052814104323, Train Acc:0.5507857777777778 Val Acc : 0.5304\n","Epoch 29: Training Loss : 0.693571555581918, Train Acc:0.5528 Val Acc : 0.5348\n","Epoch 30: Training Loss : 0.6935275290484267, Train Acc:0.5547928888888889 Val Acc : 0.5388\n","Epoch 31: Training Loss : 0.6934817585368118, Train Acc:0.5555413333333333 Val Acc : 0.5404\n","Epoch 32: Training Loss : 0.6934321463952321, Train Acc:0.5583484444444444 Val Acc : 0.548\n","Epoch 33: Training Loss : 0.6933811355786776, Train Acc:0.5617315555555555 Val Acc : 0.5504\n","Epoch 34: Training Loss : 0.6933178490553467, Train Acc:0.5646915555555555 Val Acc : 0.5532\n","Epoch 35: Training Loss : 0.6932534874069775, Train Acc:0.5655964444444445 Val Acc : 0.5576\n","Epoch 36: Training Loss : 0.693185004728115, Train Acc:0.5678275555555556 Val Acc : 0.558\n","Epoch 37: Training Loss : 0.6931041412189113, Train Acc:0.5714026666666666 Val Acc : 0.5576\n","Epoch 38: Training Loss : 0.6930174087148325, Train Acc:0.5741013333333334 Val Acc : 0.5588\n","Epoch 39: Training Loss : 0.692929090106681, Train Acc:0.5743413333333334 Val Acc : 0.5596\n","Epoch 40: Training Loss : 0.6928248028317281, Train Acc:0.5760373333333333 Val Acc : 0.5612\n","Epoch 41: Training Loss : 0.692694077853383, Train Acc:0.5803093333333333 Val Acc : 0.5648\n","Epoch 42: Training Loss : 0.6925628685158243, Train Acc:0.5836746666666667 Val Acc : 0.566\n","Epoch 43: Training Loss : 0.6924003391961456, Train Acc:0.585552 Val Acc : 0.5688\n","Epoch 44: Training Loss : 0.6922326668749533, Train Acc:0.5878773333333334 Val Acc : 0.5692\n","Epoch 45: Training Loss : 0.6920375268433312, Train Acc:0.5891537777777778 Val Acc : 0.5724\n","Epoch 46: Training Loss : 0.6917830399517709, Train Acc:0.5926524444444444 Val Acc : 0.572\n","Epoch 47: Training Loss : 0.6914744818174695, Train Acc:0.5951591111111111 Val Acc : 0.574\n","Epoch 48: Training Loss : 0.6910989869519794, Train Acc:0.5976622222222222 Val Acc : 0.5764\n","Epoch 49: Training Loss : 0.6906044939769577, Train Acc:0.6017368888888889 Val Acc : 0.5816\n"]}],"source":["model.fit(x_train,y_train,x_val,y_val,epochs=50,batch_size=128,lr=1)\n","\n"]},{"cell_type":"markdown","source":["Test Accuracy"],"metadata":{"id":"jDh-j_inGo3W"}},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":395,"status":"ok","timestamp":1652522932504,"user":{"displayName":"Rohith Rajesh","userId":"09025646982647274569"},"user_tz":-330},"id":"AVxHkd92RMa9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fba354a9-acd4-4269-99a4-3375d0f9a439"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.70536\n"]}],"source":["y_pred= model.predict(x_test)\n","print(model.accuracy(y_pred,y_test))"]},{"cell_type":"markdown","source":["Saving and loading Model "],"metadata":{"id":"1E5eWvhqGkpB"}},{"cell_type":"code","source":["import pickle\n","with open('model_fin.pickle','wb') as file:\n","  pickle.dump(model,file)"],"metadata":{"id":"sx7NRYGeUzH6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title\n","import pickle\n","with open('model_fin.pickle','rb') as file2:\n","  model_load=pickle.load(file2)\n"],"metadata":{"id":"MLoXsTJvU_U8","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yWalHc4V53an","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652522289427,"user_tz":-330,"elapsed":635,"user":{"displayName":"Rohith Rajesh","userId":"09025646982647274569"}},"outputId":"eeeec095-0509-4308-a339-6f586b75327d"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.86632\n"]}],"source":["y_pred= model_load.predict(x_test)\n","print(model_load.accuracy(y_pred,y_test))"]},{"cell_type":"code","source":[""],"metadata":{"id":"tSW98sSPvvZF"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"neural_network.ipynb","provenance":[],"mount_file_id":"1JRBKZlp0qthkfPxBp1O_G7IC2ioRFtEt","authorship_tag":"ABX9TyPlmaXHPzslk7yPRBtmSRzQ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}